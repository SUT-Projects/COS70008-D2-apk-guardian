# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D7Cd2N1JbEhHA-qBySRk6y629v-TDAQc
"""

# from google.colab import files
# uploaded = files.upload()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import joblib
from tensorflow.keras.models import save_model
from os import path, makedirs


filename = 'datasets/apk-dataset.csv'  # your file name
df = pd.read_csv(path.join(path.dirname(__file__), filename))

print("First 5 rows of dataset:")
df.head()

X = df.drop(columns=['class'])
y = df['class']

print(f"Features shape: {X.shape}")
print(f"Target shape: {y.shape}")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the input dimension based on your data
input_dim = X_train.shape[1]

# Define encoding layer sizes
encoding_dim1 = 128
encoding_dim2 = 64

# Build the autoencoder model
input_layer = Input(shape=(input_dim,))
encoded1 = Dense(encoding_dim1, activation='relu')(input_layer)
encoded2 = Dense(encoding_dim2, activation='relu')(encoded1)

decoded1 = Dense(encoding_dim1, activation='relu')(encoded2)
decoded2 = Dense(input_dim, activation='sigmoid')(decoded1)

autoencoder = Model(inputs=input_layer, outputs=decoded2)

autoencoder.compile(optimizer='adam', loss='mse')

# Train the autoencoder
autoencoder.fit(X_train, X_train,
                epochs=50,
                batch_size=32,
                shuffle=True,
                validation_data=(X_test, X_test))

# Create encoder model for feature extraction
encoder = Model(inputs=input_layer, outputs=encoded2)

# Transform the data using encoder
X_train_encoded = encoder.predict(X_train)
X_test_encoded = encoder.predict(X_test)

logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train_encoded, y_train)

# Predict and evaluate
y_pred = logreg.predict(X_test_encoded)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy of stacked autoencoder + Logistic Regression:", accuracy)

# Predict on test data
y_pred = logreg.predict(X_test_encoded)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}\n")

# Classification report (precision, recall, f1-score)
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=logreg.classes_, yticklabels=logreg.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Ensure the model directory exists
model_dir = path.join(path.dirname(__file__), 'model')
makedirs(model_dir, exist_ok=True)

# Save the logistic regression model
joblib.dump(logreg, path.join(model_dir, 'logistic_model.pkl'))

# Save the scaler
joblib.dump(scaler, path.join(model_dir, 'scaler.pkl'))

# Save the encoder model (autoencoder encoder part)
encoder.save(path.join(model_dir, 'encoder_model.h5'))

# Save the logistic regression model
joblib.dump(logreg, path.join(model_dir, 'logistic_model.pkl'))

# Save the scaler
joblib.dump(scaler, path.join(model_dir, 'scaler.pkl'))

# Save the encoder model (autoencoder encoder part)
encoder.save(path.join(model_dir, 'encoder_model.h5'))

# Save logistic regression model
joblib.dump(logreg, path.join(model_dir, 'logistic_model.pkl'))

# Save the StandardScaler
joblib.dump(scaler, path.join(model_dir, 'scaler.pkl'))

# Save the encoder part of the autoencoder in the recommended Keras format
encoder.save(path.join(model_dir, 'encoder_model.keras'))  # âœ… New format
# OR use save_model explicitly:
# save_model(encoder, 'encoder_model.keras')